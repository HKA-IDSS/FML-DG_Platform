{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a09cc2",
   "metadata": {},
   "source": [
    "# Notebook de preprocesamiento para el experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6bacc",
   "metadata": {},
   "source": [
    "El objetivo de este experimento es lanzar un entrenamiento federado para lograr un modelo entrenado con tres datasets aislados. En usuario tendra uno de ellos. El objetivo es comunicarse con los otros 3 compañeros en como establecer un dataset con una estructura común, y lanzar el entrenamiento. Para ello, se espera que los usuarios de este notebook realicen lo siguiente:\n",
    "\n",
    "\n",
    "- Construir el dataset con la misma estructura o proponer otra versión del dataset. Para construir el dataset:\n",
    "    - Ordenar las columnas del dataset en el mismo orden del dataset definido en la plataforma.\n",
    "    - Eliminar las columnas que puedan sobrar, o crear aquellas que falten.\n",
    "        - Si va a crear columnas, es recomendable rellenarlas con un único valor, para no introducir ruido en el dataset.\n",
    "- Preprocesar el dataset para:\n",
    "    - Escalar los valores numericos a la misma escala que los otros participantes.\n",
    "    - Procesar los valores categoricos para transformarlos en valores numericos, ya sea en forma de lista, o de one-hot-encoded (una columna por valor, todas a 0 excepto aquella que correspondia al valor original, que se establece a 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2803bd",
   "metadata": {},
   "source": [
    "En esta parte del código, se espera que el alumno preprocese los datos para el entrenamiento. Debido a que la información que cada silo (participante dentro del grupo) contiene es diferente, es necesario que intercambieis cierta información antes de procesar los datos, para no generar inconsistencias.\n",
    "\n",
    "Para la parte de la plataforma, solo es necesario modificar el dataset a nivel de crear o eliminar columnas. El preprocesamiento es realizado por la plataforma.\n",
    "\n",
    "**Nota: Las clases (label) ya se han proporcionado en la parte superior del notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6f1cc",
   "metadata": {},
   "source": [
    "## Petición: Mejor no tocar el codigo hasta que no se indique. Por temas de consistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf60289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ad72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dataset = \"wine_dataset_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b28daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(f\"data/raw_data/{name_dataset}.csv\", index_col=0)\n",
    "y = dataset.pop(\"label\")\n",
    "# y = y.apply(str)\n",
    "X = dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3380f3",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "In the following block, we provide with an example on how to call the functions for preprocessing the datasets. Each preprocessing function is meant to preprocess a type of data, either numerical or categorical, and it requires the name of the column, as well as some additional information. The list is the following:\n",
    "- *Min max scaler* (numérico): Toda la información se reescala en base al valor mínimo y máximo de la columna, pasando el valor máximo a ser 1, y el mínimo 0.\n",
    "    - Ejemplo: [0, 1, 2] -> [0, 0.5, 1]\n",
    "    - Input: Column (X), minimum global value, maximum global value.\n",
    "- *Label Encoder* (categórico): A cada valor categórico se le asigna un valor númerico equivalente, partiendo de 0 hasta considerar todas las categorías. Importante: Este encoder genera una lista que se puede interpretar como un order jerarquico.\n",
    "    - Ejemplo: [rojo, azul, verde] -> [0, 1, 2]\n",
    "    - Input: Columna (X), lista con todas las categorias.\n",
    "- One hot encoder (categórico): Por cada valor categórico se genera un vector de N dimensiones, siendo N el número de categorias que se encuentran en la columna. El vector tiene todos los valores a 0 exceptuando el de la categoría original, que se encuentra a 1.\n",
    "    - Ejemplo: [rojo, azul, verde] -> [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "    - Input: Columna, lista con todas las categorias.\n",
    "\n",
    "**Nota: Aunque en las siguientes funciones tienen como parametro de entrada la X, dicha X representa una columna. La y (la etiqueta de objetivo) tambien puede considerarse una columna, y procesarse con estas funciones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X, global_min, global_max):\n",
    "    X = (X - global_min) / (global_max - global_min)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_column(X, categories):\n",
    "    encoded_dataframe = pd.DataFrame()\n",
    "    X = X.str.strip()\n",
    "    X = X.str.lower()\n",
    "    for category in categories:\n",
    "        category = category.strip()\n",
    "        category = category.lower()\n",
    "        encoded_dataframe[category] = X == category\n",
    "        encoded_dataframe[category] = encoded_dataframe[category].astype(int)\n",
    "    # encoded_dataframe[X.loc[:]] = 1\n",
    "    return encoded_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(X, categories):\n",
    "    map_categories = {category: number for category, number in zip(categories, range(len(categories)))}\n",
    "    return X.map(map_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509eea3",
   "metadata": {},
   "source": [
    "Para usar las funciones de preprocesamiento, tenemos que usar la columna del dataset, y pasarla a la función. Abajo puede encontrar un ejemplo para cada una de las funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before preprocessing\n",
    "display(X[\"alcohol\"].head())\n",
    "\n",
    "# Min Max Scaler\n",
    "display(min_max_scaler(X[\"alcohol\"], 10, 20).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d902340",
   "metadata": {},
   "source": [
    "### Funciones adicionales de preprocesamiento\n",
    "\n",
    "Ordenar columnas: Para ordenar columnas del dataframe o dataset, simplemente seleccione las columnas en el orden necesario. Para ello, seleccione las columnas de las siguiente forma: X[[primera_columna, segunda_columna, ...]].\n",
    "\n",
    "Eliminar columnas: Para ello, simplemente no la incluya en la lista para ordenar.\n",
    "\n",
    "Crear columnas: Para crear una columna, simplemente seleccione el dataset y la columna, e introduzca el valor de la siguiente forma:\n",
    "X[\"columna\"] = valor\n",
    "\n",
    "Cambiar valores de categorias en la columna:\n",
    "X[\"columna\"] = X[\"columna\"].map{\"categoria_original_1\": \"categoria_a_cambiar_1\", \"categoria_original_2\": \"categoria_a_cambiar_2\", ...}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27b23a",
   "metadata": {},
   "source": [
    "## En esta sección es donde se espera que escribais algo de código. Abra una indicación al final de la misma.\n",
    "\n",
    "En esta parte del código, se espera que el alumno preprocese los datos para el entrenamiento. Debido a que la información que cada silo (participante dentro del grupo) contiene es diferente, es necesario que intercambieis cierta información antes de procesar los datos, para no generar inconsistencias.\n",
    "\n",
    "La información sería:\n",
    "- Nombres de las columnas, y orden. Nombres de las columnas, y orden. Importante que sea el mismo para todos los participantes.\n",
    "- Valores máximos y mínimos de las columnas númericas (si min max encoder). Formato: Dos valores númericos por separado.\n",
    "- Valores categóricos de las columnas categóricas (si label encoder o one hot encoder). Formato: Es una lista.\n",
    "\n",
    "**Nota: Las clases (label) ya se ha proporcionado en la parte superior del notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6747c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cba2575",
   "metadata": {},
   "source": [
    "## Final de la sección de código a modificar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20b6fc",
   "metadata": {},
   "source": [
    "## A partir de aquí, mejor no tocar. Simplemente ejecute uno a uno los bloques de código.\n",
    "\n",
    "Para realizar una tarea de clasificación, es necesario que usemos el one-hot-encoder en la columna de la etiqueta (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot_encoded: pd.DataFrame = one_hot_encode_column(y, [\"red\", \"white\", \"sparkling\"])\n",
    "y_one_hot_sorted = y_one_hot_encoded.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2798a",
   "metadata": {},
   "source": [
    "Aquí se realiza la división de datos entre entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_sorted, random_state=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a5479",
   "metadata": {},
   "source": [
    "Finalmente, se almacenan dichos datos para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(f\"data/training_data_preprocessed/{name_dataset}\", exist_ok=True)\n",
    "X_train.to_csv(f\"data/training_data_preprocessed/{name_dataset}/\" + \"X_train.csv\")\n",
    "X_test.to_csv(f\"data/training_data_preprocessed/{name_dataset}/\" + \"X_test.csv\")\n",
    "y_train.to_csv(f\"data/training_data_preprocessed/{name_dataset}/\" + \"y_train.csv\")\n",
    "y_test.to_csv(f\"data/training_data_preprocessed/{name_dataset}/\" + \"y_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fltrainingexperiments-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
